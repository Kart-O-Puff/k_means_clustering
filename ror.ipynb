{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is where we import the libraries we will need for this assignment.\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from kneed import KneeLocator\n",
    "\n",
    "random.seed('spearhead')\n",
    "\n",
    "#To reduce memory usage, we enable copy-on-write mode to avoid making unnecessary copies of the dataframe.\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we load the dataset in a dataframe named \"data_table\".\n",
    "data_table = pd.read_csv('Mall_Customers.csv')\n",
    "\n",
    "#Here, we just display the metadata (column header, missing values, data type) of the dataset:\n",
    "data_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove data with null values and adjust the index of the dataset.\n",
    "adjusted_dataset = data_table.dropna()\n",
    "adjusted_dataset = adjusted_dataset.reset_index(drop=True)\n",
    "\n",
    "#Here, we just display the metadata (column header, missing values, data type) of the dataset:\n",
    "adjusted_dataset.info()\n",
    "\n",
    "#We see that there are no data with missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we select these three features to use for K Means Clustering.\n",
    "feature1='age'\n",
    "feature2='annual_income'\n",
    "feature3='spending_score'\n",
    "\n",
    "#Then, we create a dataframe containing only these three features (omitting gender).\n",
    "k_mean_df = adjusted_dataset[[feature1, feature2, feature3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we visualize the original state of the dataset with a scatter plot having three features.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(k_mean_df[feature1], k_mean_df[feature2], k_mean_df[feature3], alpha=0.6)\n",
    "ax.set_xlabel(feature1)\n",
    "ax.set_ylabel(feature2)\n",
    "ax.set_zlabel(feature3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the function to plot centroids in random positions (as an initial guess).\n",
    "def randompoint(feature):\n",
    "  min = k_mean_df[feature].min()\n",
    "  max = k_mean_df[feature].max()\n",
    "  return random.randint(min.astype(np.int64), max.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a loop for our k means clustering algorithm\n",
    "wcss = np.array([])\n",
    "\n",
    "first_centroid = 1\n",
    "last_centroid = 8\n",
    "\n",
    "for k in range(first_centroid, last_centroid+1):\n",
    "    print('\\n \\nNumber of centroids = ', k)\n",
    "    number_centroids = k\n",
    "    centroids = np.array([[randompoint(feature1), randompoint(feature2), randompoint(feature3)] for _ in range(number_centroids)])\n",
    "\n",
    "    before_wcss = 0\n",
    "\n",
    "    itr = 1\n",
    "    while (True):\n",
    "        print('\\nIteration Counter = ', itr)\n",
    "\n",
    "        #This is how we compute for the distances of the datapoints to the centroids using the Euclidean distance formula where we take the positive values (that's why the values are squared)\n",
    "        def compute_distances(df, centroids):\n",
    "            distances = []\n",
    "            for x in range(df.shape[0]):\n",
    "                point = [df.iloc[x][feature1], df.iloc[x][feature2], df.iloc[x][feature3]]\n",
    "                point_distances = []\n",
    "                for centroid in centroids:\n",
    "                    distance = ((point[0] - centroid[0]) ** 2 + (point[1] - centroid[1]) ** 2 + (point[2] - centroid[2]) ** 2) ** 0.5\n",
    "                    point_distances.append(distance)\n",
    "                distances.append(point_distances)\n",
    "            return np.array(distances)\n",
    "\n",
    "        distances_centroids = compute_distances(k_mean_df, centroids)\n",
    "\n",
    "        #Then, we assign the datapoint to the nearest centroid based from its distance values towards the centroids.\n",
    "        # - np.argmin(x) finds the index of the nearest centroid for each point.\n",
    "        # - np.min(x) retrieves the corresponding minimum distance value.\n",
    "        index_centroids = np.array([[np.argmin(x), np.min(x)] for x in distances_centroids])\n",
    "\n",
    "        #We store the assignment of the clusters for each datapoint.\n",
    "        k_mean_df['nearest_centroids'] = index_centroids[:, 0]\n",
    "\n",
    "        #Then, we store the distances for computing WCSS (Within-Cluster Sum of Squares) later\n",
    "        current_wcss = index_centroids[:, 1].sum()\n",
    "        print('WCSS in this iteration = ', current_wcss)\n",
    "\n",
    "        #For Visualization\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(k_mean_df[feature1], k_mean_df[feature2], k_mean_df[feature3], c=k_mean_df['nearest_centroids'], cmap='viridis', alpha=0.5)\n",
    "        centroid_x = centroids[:, 0]\n",
    "        centroid_y =centroids[:, 1]\n",
    "        centroid_z =centroids[:, 2]\n",
    "        ax.scatter(centroid_x, centroid_y, centroid_z, c=range(len(centroids)), cmap='viridis', marker='*', s=100, label='Centroids', alpha=1.0)\n",
    "        ax.set_xlabel(feature1)\n",
    "        ax.set_ylabel(feature2)\n",
    "        ax.set_zlabel(feature3)\n",
    "        plt.show()\n",
    "\n",
    "        #New centroids are plotted, by again getting the average or mean\n",
    "        new_centroids = k_mean_df.groupby(by=['nearest_centroids']).mean()\n",
    "        centroids = np.array([[new_centroids.iloc[i][feature1], new_centroids.iloc[i][feature2], new_centroids.iloc[i][feature3]] for i in range(len(new_centroids))])\n",
    "\n",
    "        #Go to next iteration\n",
    "        itr+=1\n",
    "\n",
    "        #Stop iteration if the values of WCSS has not changed from the previous iteration\n",
    "        #If WCSS remains the same, it means the centroids have stabilized, so we may now stop looping.\n",
    "        if (before_wcss == current_wcss):\n",
    "            print('\\nWCSS in this iteration = ', current_wcss)\n",
    "            wcss = np.append(wcss, current_wcss)\n",
    "            break\n",
    "        before_wcss = current_wcss\n",
    "\n",
    "        #Here is where we print cluster assignments\n",
    "        print('Cluster Assignment after the iteration: \\n', k_mean_df.groupby(by=['nearest_centroids']).count())\n",
    "    \n",
    "    print('Final WCSS for this k Cluster = ', before_wcss)\n",
    "\n",
    "    print('\\nFinal Cluster Assignment from the Converged K Means: ', k_mean_df.groupby(by=['nearest_centroids']).count())\n",
    "\n",
    "print('\\nFinal WCSS for all k Clusters tested: ', wcss)\n",
    "\n",
    "#Plot the Elbow Method Graph\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "len_wcss = [i+1 for i in range(len(wcss))]\n",
    "\n",
    "print(wcss)\n",
    "\n",
    "ax.plot(len_wcss, wcss, 'o-', linewidth=2)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
